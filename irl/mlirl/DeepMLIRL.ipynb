{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.use('Agg')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Utils\n",
    "sys.path.append(\"../../irl/\")\n",
    "from IRLProblem import IRLProblem\n",
    "\n",
    "# GeoLife\n",
    "sys.path.append(\"../../dataset/GeolifeTrajectories1.3/\")\n",
    "import geolife_data as GLData\n",
    "\n",
    "# MLIRL\n",
    "from mlirl_parallel import *\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps_api_key = 'AIzaSyCEQD8gqNXicATEstzFwCtFOlRWWWRrX4k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRL Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "GEOLIFE_DIR = \"../../dataset/GeolifeTrajectories1.3/\"\n",
    "IMAGE_FEATURE_DIR = \"./features/satellite_rgb/\"\n",
    "traj_split = [0.6, 0.3, 0.1]\n",
    "rand_split = False\n",
    "max_traj_length = 30 # for debugging, -1 to disable\n",
    "recompute_envelope = True\n",
    "state_expl_cost_bound = 1.1 # only works if above flag is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoLife2(IRLProblem):\n",
    "    \n",
    "    def __init__(self, data_dir=\"../../dataset/GeolifeTrajectories1.3/\",\n",
    "                 satimg_dir=\"./features/satellite_rgb/\",\n",
    "                 satimg_zoom=19,\n",
    "                 satimg_dim=(1,128,128), \n",
    "                 feature_mu=0., \n",
    "                 feature_std=1.,\n",
    "                 lat_resolution=0.00010952786669320442,\n",
    "                 lng_resolution=0.00014278203208415482,\n",
    "                 st_fp_precision=20):\n",
    "        \n",
    "        with open(os.path.join(data_dir, \"chopped_trajectories/turn_trajectories/turn_trajectories_v1.pk\"), \"rb\") as f:\n",
    "            self.trajectories = pickle.load(f)\n",
    "            \n",
    "        self.satimg_dir = satimg_dir\n",
    "        self.satimg_zoom = satimg_zoom\n",
    "        self.satimg_dim = satimg_dim\n",
    "        self.feature_mu = feature_mu\n",
    "        self.feature_std = feature_std\n",
    "        self.lat_resolution = lat_resolution\n",
    "        self.lng_resolution = lng_resolution\n",
    "        self.st_fp_precision = st_fp_precision\n",
    "    \n",
    "    def features(self, state, feature_dim, gmaps_api_key=None, verbose=False):\n",
    "        \n",
    "        cc, hh, ww = feature_dim\n",
    "        _, h, w = self.satimg_dim\n",
    "        \n",
    "        crop_top, crop_bottom = int(np.floor((h - hh) / 2)), int(np.ceil((h - hh) / 2))\n",
    "        crop_left, crop_right = int(np.floor((w - ww) / 2)), int(np.ceil((w - ww) / 2))\n",
    "        \n",
    "        mode = \"L\" if cc == 1 else \"RGB\"\n",
    "        img_size = str(h) +\"x\" + str(w)\n",
    "        \n",
    "        img = GLData.feature(state, img_size=img_size,\n",
    "                             zoom=self.satimg_zoom, mode=mode,\n",
    "                             api_key=gmaps_api_key, verbose=verbose,\n",
    "                             store_dir=self.satimg_dir)\n",
    "        if mode == \"L\":\n",
    "            img_crop = img[crop_top:-crop_bottom,crop_left:-crop_right]\n",
    "        else:\n",
    "            img_crop = img[crop_top:-crop_bottom,crop_left:-crop_right,:]\n",
    "            \n",
    "        return torch.FloatTensor(\n",
    "            (img_crop/255. - self.feature_mu) / self.feature_std).view(-1, cc, hh, ww)\n",
    "    \n",
    "    def sample_trajectories(self):\n",
    "        return self.trajectories\n",
    "\n",
    "    def get_dynamics(self):\n",
    "        return self._envelope_gridded_dynamics\n",
    "    \n",
    "    def _envelope_gridded_dynamics(self, s, a, lat_to_lngs):\n",
    "        \n",
    "        s_prime = GLData.trans_func(\n",
    "            s, a, \n",
    "            lat_resolution=self.lat_resolution, \n",
    "            lng_resolution=self.lng_resolution, \n",
    "            st_fp_precision=self.st_fp_precision)\n",
    "    \n",
    "        lat, lng = s_prime\n",
    "        # next state can't go far from the cell center by this amount, if it goes we're outside the border\n",
    "        lat_eps, lng_eps = self.lat_resolution/2., self.lng_resolution/2.\n",
    "\n",
    "        grid_lats = np.asarray(list(lat_to_lngs.keys())).reshape(-1,1)\n",
    "        grid_lat_dists = np.linalg.norm(grid_lats - lat, axis=1)\n",
    "        best_lat_idx = np.argmin(grid_lat_dists)\n",
    "\n",
    "        if grid_lat_dists[best_lat_idx] < lat_eps:        \n",
    "            best_lat = grid_lats[best_lat_idx][0]\n",
    "            lngs_list = lat_to_lngs[best_lat]\n",
    "\n",
    "            if len(lngs_list) == 0:\n",
    "                return None\n",
    "            else:\n",
    "                _lng_dists = np.linalg.norm(np.asarray(lngs_list).reshape(-1,1) - lng, axis=1)\n",
    "                best_lng_idx = np.argmin(_lng_dists)\n",
    "                if _lng_dists[best_lng_idx] < lng_eps:\n",
    "                    return best_lat, lngs_list[best_lng_idx]\n",
    "                else:\n",
    "                    return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "def get_geolife_problem(geolife, image_dim, max_traj_length, gmaps_api_key):\n",
    "    \n",
    "    A = [\"E\", \"N\", \"W\", \"S\"] # TODO: Need 8 actions or at least 2 turns.\n",
    "    T = geolife.get_dynamics()\n",
    "    \n",
    "    trajectories = geolife.sample_trajectories()\n",
    "    # Trim trajectories (for debugging only)\n",
    "    if max_traj_length != -1:\n",
    "        for idx, t in enumerate(trajectories):\n",
    "            trajectories[idx] = (t[0][:max_traj_length], t[1][:max_traj_length])\n",
    "            \n",
    "    S_list = []\n",
    "    phi = lambda s: geolife.features(s, image_dim, gmaps_api_key=gmaps_api_key)\n",
    "    S_lat_to_lngs_list = []\n",
    "    for trajectory in trajectories:\n",
    "        S, expert_cost = GLData.find_enevelope_a_star(\n",
    "                    trajectory, A, GLData.trans_func, geolife.lat_resolution, geolife.lng_resolution, \n",
    "                        cost_ubound=1.1,\n",
    "                        g_fn=lambda p1, p2, lat_res, lng_res: GLData.heuristic_l1(p1, p2, lat_res, lng_res),\n",
    "                        h_fn=lambda p1, p2, lat_res, lng_res: GLData.heuristic_l2(p1, p2, lat_res, lng_res),)\n",
    "        S_list.append(S)\n",
    "        S_lat_to_lngs = defaultdict(lambda: [])\n",
    "        for (lat, lng) in S:\n",
    "            S_lat_to_lngs[lat].append(lng)\n",
    "        S_lat_to_lngs_list.append(S_lat_to_lngs)\n",
    "    return trajectories, S_list, phi, A, T, S_lat_to_lngs_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim=(1,64,64)\n",
    "trajectories, S_list, phi, A, T, S_lat_to_lngs_list = get_geolife_problem(\n",
    "    GeoLife2(GEOLIFE_DIR, IMAGE_FEATURE_DIR), image_dim, max_traj_length, gmaps_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train traj idxs [4, 25, 10, 31, 27, 11, 36, 28, 20, 38, 2, 40, 18, 15, 22, 16, 37, 8, 13, 5, 17]\n",
      "Val traj idxs [14, 34, 7, 33, 1, 26, 12, 32, 24, 6, 23, 21]\n",
      "Test traj idxs [19, 9, 39, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "N = len(trajectories)\n",
    "N_tr = int(traj_split[0] * N)\n",
    "N_val = int(traj_split[1] * N)\n",
    "N_te = N - N_tr - N_val\n",
    "\n",
    "if rand_split:\n",
    "    rand_idxs = np.random.permutation(len(trajectories))\n",
    "    tr_idxs = rand_idxs[:N_tr]\n",
    "    val_idxs = rand_idxs[N_tr: N_tr+N_val]\n",
    "    te_idxs = rand_idxs[N_tr+N_val:]\n",
    "else:\n",
    "    tr_idxs = [4, 25, 10, 31, 27, 11, 36, 28, 20, 38, 2, 40, 18, 15, 22, 16, 37, 8, 13, 5, 17]\n",
    "    val_idxs = [14, 34, 7, 33, 1, 26, 12, 32, 24, 6, 23, 21]\n",
    "    te_idxs = [19, 9, 39, 3, 0]\n",
    "    \n",
    "print(\"Train traj idxs\", tr_idxs)\n",
    "print(\"Val traj idxs\", val_idxs)\n",
    "print(\"Test traj idxs\", te_idxs)\n",
    "\n",
    "train_trajectories = [trajectories[idx] for idx in tr_idxs]\n",
    "val_trajectories = [trajectories[idx] for idx in val_idxs]\n",
    "test_trajectories = [trajectories[idx] for idx in te_idxs]\n",
    "\n",
    "train_S_lat_to_lngs_list = [S_lat_to_lngs_list[idx] for idx in tr_idxs]\n",
    "val_S_lat_to_lngs_list = [S_lat_to_lngs_list[idx] for idx in val_idxs]\n",
    "test_S_lat_to_lngs_list = [S_lat_to_lngs_list[idx] for idx in te_idxs]\n",
    "\n",
    "train_S_list  = [S_list[idx] for idx in tr_idxs]\n",
    "val_S_list  = [S_list[idx] for idx in val_idxs]\n",
    "test_S_list  = [S_list[idx] for idx in te_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7f36871cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Net..\n",
      "NW Config (depth=17):\n",
      "\tBlock: [('conv1', 16), ('relu1', None)]\n",
      "\tNet: \n",
      "[('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv-strided1', 16),\n",
      " ('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv1', 16),\n",
      " ('relu1', None),\n",
      " ('conv-strided1', 16),\n",
      " ('flatten1', None),\n",
      " ('linear1', 512),\n",
      " ('linear1', 128)]\n",
      "\n",
      "Creating model..\n",
      "Loading states from: ../../models/EXP_GEOLIFE_FEATURES_CONVAE_STRIDED_FINE_STATES_CHOPPED_TRAJ/states=100x100$img_size=128x128$conv_k_size=16$fc_latent_multiplier=4$code_size=128$strided_conv_freq=3$lr=0.0001$weight_decay=1e-09/results/model_state_ae.pt\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# ConvAE\n",
    "sys.path.append(\"../../models/\")\n",
    "import ConvAE as ConvAE\n",
    "from pprint import pprint\n",
    "\n",
    "# arch\n",
    "nw_depth = 6\n",
    "conv_k_size = 16\n",
    "fc_latent_multiplier = 4\n",
    "code_size = 128\n",
    "strided_conv_freq = 3\n",
    "use_convae_phi_priors = True\n",
    "convae_model_state = \"../../models/EXP_GEOLIFE_FEATURES_CONVAE_STRIDED_FINE_STATES_CHOPPED_TRAJ/\"\\\n",
    "    \"states=100x100$img_size=128x128$conv_k_size=16$fc_latent_multiplier=4$\"\\\n",
    "    \"code_size=128$strided_conv_freq=3$lr=0.0001$weight_decay=1e-09/results/model_state_ae.pt\"\n",
    "model_restore_file = None # to restore weights\n",
    "\n",
    "# training\n",
    "lr = 0.0005\n",
    "weight_decay = 1e-4\n",
    "optimizer_fn = lambda params, lr, weight_decay: optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        \n",
    "# Architecture\n",
    "print(\"\\nPreparing Net..\")\n",
    "CONV_BLOCK = [(\"conv1\", conv_k_size), (\"relu1\", None)]\n",
    "CONV_LAYERS = ConvAE.create_network(CONV_BLOCK, nw_depth, pooling_freq=1e100,\n",
    "                                    strided_conv_freq=strided_conv_freq, strided_conv_channels=conv_k_size)\n",
    "CONV_NW = CONV_LAYERS + [(\"flatten1\", None),\n",
    "                         (\"linear1\", fc_latent_multiplier * code_size), (\"linear1\", code_size), ]\n",
    "\n",
    "print(\"NW Config (depth={}):\\n\\tBlock: \".format(len(CONV_NW)), end=\"\")\n",
    "pprint(CONV_BLOCK)\n",
    "print(\"\\tNet: \\n\", end=\"\")\n",
    "pprint(CONV_NW)\n",
    "\n",
    "print(\"\\nCreating model..\")\n",
    "# https://discuss.pytorch.org/t/how-can-we-release-gpu-memory-cache/14530\n",
    "# torch.cuda.empty_cache() # Needed for repeated experiments\n",
    "if use_convae_phi_priors:\n",
    "    convae = ConvAE.ConvAE(image_dim, enc_config=CONV_NW, states_file=convae_model_state)\n",
    "else:\n",
    "    convae = ConvAE.ConvAE(input_dim, \n",
    "                      enc_config=CONV_NW)\n",
    "encoder = nn.Sequential(*convae.encoder)\n",
    "encoder2 = copy.deepcopy(encoder)\n",
    "decoder = nn.Sequential(*convae.decoder)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"\\n\\nUsing device {}\".format(device))\n",
    "# encoder.to(device)\n",
    "# decoder.to(device)\n",
    "    \n",
    "phi_dim = code_size\n",
    "if model_restore_file is not None:\n",
    "    with open(model_restore_file, \"rb\") as mlirl_model:\n",
    "        print(\"Restoring model from {}\".format(model_restore_file))\n",
    "        M = pickle.load(mlirl_model)\n",
    "else:\n",
    "    M = LinearRewardModel(phi_dim)\n",
    "    M.apply(weights_init)\n",
    "\n",
    "# Feature Encoding  + Linear Model \n",
    "# (Using two separate models so that features can be pretrained using ConvAE. \n",
    "# Encoder: 1x64x64 -> code size, Linear: code_size -> 1)\n",
    "encoder.add_module(\"R\", M)\n",
    "\n",
    "def dec_model(encoding): \n",
    "    with torch.no_grad():\n",
    "        return decoder(encoding)\n",
    "    \n",
    "# ConvAE features fixed, only scalar R mapping is learned\n",
    "#     for param in M.parameters():\n",
    "#         param.grad = Variable(torch.zeros(param.shape))\n",
    "#     M.share_memory() \n",
    "\n",
    "# End to end: ConvAE features are learned end to end\n",
    "for param in encoder.parameters():\n",
    "    param.grad = Variable(torch.zeros(param.shape))\n",
    "\n",
    "# This is required for the ``fork`` method to work (https://pytorch.org/docs/master/notes/multiprocessing.html)\n",
    "encoder.share_memory()\n",
    "\n",
    "# Optimization params\n",
    "r_optimizer = optimizer_fn(encoder.parameters(), lr, weight_decay)\n",
    "\n",
    "# Test\n",
    "x = phi(S_list[0][0])\n",
    "assert torch.allclose(-nn.ReLU()(-M.w(encoder2(x)[0])), encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "def iter_handler(_iter, loss_history, r_model, results_dir=None, dec_model=None, \n",
    "                 render=False, redraw=False, params_inspection_fn=None, training_interrupted=False):\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    if training_interrupted: # i.e., training iterrupted\n",
    "        print(\"Iter: {:04d} Training interrupted! \"\n",
    "              \"Returning current states..\".format(_iter))\n",
    "        with open(os.path.join(results_dir, \"./interrupted_mlirl_iter_model.pkl\"), \"wb\") as model_file:\n",
    "            pickle.dump(r_model, model_file)\n",
    "        return\n",
    "    \n",
    "    if params_inspection_fn:\n",
    "        params_inspection_fn(_iter, r_model)\n",
    "    \n",
    "    if results_dir:\n",
    "        with open(os.path.join(results_dir, \"./mlirl_iter_{:03d}_model.pkl\".format(\n",
    "                _iter)), \"wb\") as model_file:\n",
    "            pickle.dump(r_model, model_file)            \n",
    "        # Remove previous backup\n",
    "        if _iter > 0:\n",
    "            os.remove(os.path.join(results_dir, \"./mlirl_iter_{:03d}_model.pkl\".format(\n",
    "                _iter-1)))\n",
    "            \n",
    "    if render and redraw:\n",
    "        plt.gca().cla()\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    plt.subplot(211)\n",
    "\n",
    "    if dec_model is not None:\n",
    "        with torch.no_grad():\n",
    "            out = dec_model(torch.FloatTensor(r_model[-1].w.weight.detach().data.numpy())).detach().data\n",
    "            plt.imshow(out[0, 0].data, cmap=\"gray\")\n",
    "            plt.title(\"Max likelihood image\")\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(np.exp(-np.asarray(loss_history)))\n",
    "    plt.title(\"Linear MLIRL (GeoLife Trajectories)\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Likelihood\")\n",
    "    \n",
    "    if results_dir:\n",
    "        plt.savefig(os.path.join(results_dir, \"mlirl_iter_{:03d}_plot.png\".format(_iter)))\n",
    "        if _iter > 0:\n",
    "            os.remove(os.path.join(results_dir, \"mlirl_iter_{:03d}_plot.png\".format(_iter-1)))\n",
    "            \n",
    "    if render:     \n",
    "        if redraw:\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "def params_inspection_fn(_iter, r_model):\n",
    "    \n",
    "    for p in r_model.parameters():\n",
    "        print(\"\\n\\t\\t\\t Params @ Iter {}\"\n",
    "              \"\\n\\t\\t\\t\\t     w: [{}]\"\n",
    "              \"\\n\\t\\t\\t\\t    dw: [{}]\".format(\n",
    "                  _iter,\n",
    "                  ' '.join(\"{:+012.7f}\".format(v) for v in p[0, 0].flatten()),\n",
    "                  ' '.join(\"{:+012.7f}\".format(v) for v in p.grad[0, 0].flatten()))\n",
    "              )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep MLIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tForking process #0..\n",
      "\t\tRunning process: 0, traj len: 30, states: 422\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = \"./__mlirl_results/\"\n",
    "r_model, loss_history, Pi_list, V_list, Q_list = MLIRL(\n",
    "    train_trajectories, train_S_list, phi, A, T, train_S_lat_to_lngs_list, \n",
    "    r_model=encoder, r_optimizer=r_optimizer,\n",
    "    n_iter=20,\n",
    "    n_vi_iter=200, \n",
    "    gamma=0.95, \n",
    "    boltzmann_temp=1.,\n",
    "    loss_eps=1e-3,\n",
    "    max_goals=4,\n",
    "    dtype=torch.float64,\n",
    "    debug=True, \n",
    "    verbose=True, \n",
    "    perf_debug=True, \n",
    "    max_processes=1,\n",
    "    iter_handler=iter_handler,\n",
    "    results_dir=RESULTS_DIR,\n",
    "    dec_model=dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
